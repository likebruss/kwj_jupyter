{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(s) = 4\n",
      "b = b'caf\\xc3\\xa9'\n",
      "len(b) = 5\n",
      "b.decode('utf8') = café\n"
     ]
    }
   ],
   "source": [
    "# Example 4-1. Encoding and decoding.\n",
    "s = 'café'\n",
    "print('len(s) =', len(s))\n",
    "b = s.encode('utf8')\n",
    "print('b =', b)\n",
    "print('len(b) =', len(b))  #  “é” is encoded as two bytes in UTF-8\n",
    "print(\"b.decode('utf8') =\", b.decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cafe = b'caf\\xc3\\xa9'\n",
      "cafe[0] = 99\n",
      "cafe[:3] = b'caf'\n",
      "cafe[:4] = b'caf\\xc3'\n",
      "\n",
      "caf_arre = bytearray(b'caf\\xc3\\xa9')\n",
      "cafe_arr[-1] = 169\n",
      "cafe_arr[-1:] = bytearray(b'\\xa9')\n",
      "\n",
      "bytes.fromhex =  b'1K\\xce\\xa9'\n",
      "\u001f\n"
     ]
    }
   ],
   "source": [
    "# Example 4-2. A five-byte sequence as bytes and as bytearray.\n",
    "cafe = bytes('café', encoding='utf_8')\n",
    "print('cafe =', cafe)\n",
    "print('cafe[0] =', cafe[0])\n",
    "print('cafe[:3] =', cafe[:3])  # !!!\n",
    "print('cafe[:4] =', cafe[:4])  # !!!\n",
    "print()\n",
    "cafe_arr = bytearray('café', encoding='utf_8')\n",
    "print('caf_arre =', cafe_arr)\n",
    "print('cafe_arr[-1] =', cafe_arr[-1])\n",
    "print('cafe_arr[-1:] =', cafe_arr[-1:])  # !!!\n",
    "print()\n",
    "print(\"bytes.fromhex = \", bytes.fromhex('31 4B CE A9'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "octets = b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-3. Initializing bytes from the raw data of an array.\n",
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "octets = bytes(numbers)\n",
    "print(\"octets =\", octets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'GIF89a\\x03\\x03a\\x01'\n",
      "(b'GIF', b'89a', 771, 353)\n"
     ]
    }
   ],
   "source": [
    "# Example 4-4 shows the use of memoryview and struct together to extract the width and height of a GIF image.\n",
    "import struct\n",
    "fmt = '<3s3sHH' # struct format: < little-endian; 3s3s two sequences of 3 bytes; HH two 16-bit integers.\n",
    "with open('files/EU_P-kolor.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read()) # Create memoryview from file contents in memory\n",
    "header = img[:10] # …then another memoryview by slicing the first one; no bytes are copied here.\n",
    "print(bytes(header)) # Convert to bytes for display only; 10 bytes are copied here.\n",
    "print(struct.unpack(fmt, header)) # Unpack memoryview into tuple of: type, version, width and height\n",
    "del header # Delete references to release the memory associated with the memoryview instances.\n",
    "del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\tb'El Ni\\xf1o'\n",
      "utf-8\tb'El Ni\\xc3\\xb1o'\n",
      "utf16\tb'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-5. The string “El Niño” encoded with three codecs producing very different byte sequences.\n",
    "for codec in ['latin_1', 'utf-8', 'utf16']:\n",
    "    print(codec, 'El Niño'.encode(codec), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'S\\xc3\\xa3o Paulo'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 4-6. Encoding to bytes: success and error handling\n",
    "city = 'São Paulo'\n",
    "city.encode('utf_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6f58a1962197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 4-6.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp437'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.5/encodings/cp437.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input, errors)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\xe3' in position 1: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Example 4-6.\n",
    "city.encode('cp437')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'So Paulo'\n",
      "b'S?o Paulo'\n",
      "b'S&#227;o Paulo'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-6.\n",
    "print(city.encode('cp437', errors='ignore'))\n",
    "print(city.encode('cp437', errors='replace'))\n",
    "print(city.encode('cp437', errors='xmlcharrefreplace'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "Montrιal\n",
      "Montr�al\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9d43cfb685c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iso8859_7'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf_8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moctets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf_8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 5: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Example 4-7. Decoding\n",
    "octets = b'Montr\\xe9al'\n",
    "print(octets.decode('cp1252'))\n",
    "print(octets.decode('iso8859_7'))\n",
    "print(octets.decode('utf_8', errors='replace'))\n",
    "print(octets.decode('utf_8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, Mundo!\n"
     ]
    }
   ],
   "source": [
    "# coding: cp1252\n",
    "print('Olá, Mundo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n",
      "[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n"
     ]
    }
   ],
   "source": [
    "# BOM\n",
    "u16 = 'El Niño'.encode('utf_16')\n",
    "print(u16)\n",
    "print(list(u16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n",
      "[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]\n"
     ]
    }
   ],
   "source": [
    "# Little endian / Big endian\n",
    "u16le = 'El Niño'.encode('utf_16le')\n",
    "print(list(u16le))\n",
    "u16be = 'El Niño'.encode('utf_16be')\n",
    "print(list(u16be))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafĂ©'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 4-9. A platform encoding issue. If you try this on your machine, you may or may not see the problem.\n",
    "open('files/cafeW.txt', 'w').write('café')\n",
    "open('files/cafeW.txt', encoding='cp1250').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='files/cafe.txt' mode='w' encoding='utf_8'>\n",
      "fp.write 4\n",
      "os.stat 5\n",
      "\n",
      "cp1250\n",
      "cafĂ©\n",
      "\n",
      "b'caf\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-10. Closer inspection of Example 4-9 running on Windows reveals the bug and how to fix it.\n",
    "fp = open('files/cafe.txt', 'w', encoding='utf_8')\n",
    "print(fp)\n",
    "print('fp.write', fp.write('café'))\n",
    "fp.close()\n",
    "import os\n",
    "print('os.stat', os.stat('files/cafe.txt').st_size)\n",
    "print()\n",
    "\n",
    "fp2 = open('files/cafe.txt', encoding='cp1250')\n",
    "print(fp2.encoding)\n",
    "print(fp2.read())\n",
    "print()\n",
    "\n",
    "fp4 = open('files/cafe.txt', 'rb')\n",
    "print(fp4.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'UTF-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-11. Exploring encoding defaults\n",
    "import sys, locale\n",
    "expressions = \"\"\"\n",
    "    locale.getpreferredencoding()\n",
    "    type(my_file)\n",
    "    my_file.encoding\n",
    "    sys.stdout.isatty()\n",
    "    sys.stdout.encoding\n",
    "    sys.stdin.isatty()\n",
    "    sys.stdin.encoding\n",
    "    sys.stderr.isatty()\n",
    "    sys.stderr.encoding\n",
    "    sys.getdefaultencoding()\n",
    "    sys.getfilesystemencoding()\n",
    "    \"\"\"\n",
    "my_file = open('files/dummy', 'w')\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)   # !!!\n",
    "    print(expression.rjust(30), '->', repr(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1, s2: café café\n",
      "len(s1), len(s2): 4 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing Unicode for saner comparisons\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print('s1, s2:', s1, s2)\n",
    "print('len(s1), len(s2):', len(s1), len(s2))\n",
    "s1==s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(s1), len(s2): 4 5\n",
      "NFC: len(s1), len(s2): 4 4\n",
      "NFD: len(s1), len(s2): 5 5\n",
      "\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Unicode normalisation 'NFC', 'NFD'\n",
    "from unicodedata import normalize\n",
    "s1 = 'café' # composed \"e\" with acute accent\n",
    "s2 = 'cafe\\u0301' # decomposed \"e\" and acute accent\n",
    "print('len(s1), len(s2):', len(s1), len(s2))\n",
    "print('NFC: len(s1), len(s2):', len(normalize('NFC', s1)), len(normalize('NFC', s2)))\n",
    "print('NFD: len(s1), len(s2):', len(normalize('NFD', s1)), len(normalize('NFD', s2)))\n",
    "print()\n",
    "print(normalize('NFC', s1) == normalize('NFC', s2))\n",
    "print(normalize('NFD', s1) == normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name(ohm)= OHM SIGN\n",
      "name(ohm_c)= GREEK CAPITAL LETTER OMEGA\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# ohm normalization\n",
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "print('name(ohm)=', name(ohm))\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "name(ohm_c)\n",
    "print('name(ohm_c)=', name(ohm_c))\n",
    "print(ohm == ohm_c)\n",
    "print(normalize('NFC', ohm) == normalize('NFC', ohm_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "½ 1⁄2\n",
      "4² 42\n",
      "µ μ\n",
      "181 956\n",
      "MICRO SIGN    GREEK SMALL LETTER MU\n"
     ]
    }
   ],
   "source": [
    "# NFKC normalization\n",
    "from unicodedata import normalize, name\n",
    "half = '½'\n",
    "print(half, normalize('NFKC', half))\n",
    "four_squared = '4²'\n",
    "print(four_squared, normalize('NFKC', four_squared))\n",
    "micro = 'µ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "print(micro, micro_kc)\n",
    "print(ord(micro), ord(micro_kc))\n",
    "print(name(micro),'  ', name(micro_kc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MICRO SIGN\n",
      "GREEK SMALL LETTER MU\n",
      "micro, micro_cf:  µ μ\n",
      "LATIN SMALL LETTER SHARP S\n",
      "eszett, eszett_cf: ß ss\n"
     ]
    }
   ],
   "source": [
    "# Case folding\n",
    "micro = 'µ'\n",
    "print(name(micro))\n",
    "micro_cf = micro.casefold()\n",
    "print(name(micro_cf))\n",
    "print('micro, micro_cf: ', micro, micro_cf)\n",
    "eszett = 'ß'\n",
    "print( name(eszett))\n",
    "eszett_cf = eszett.casefold()\n",
    "print('eszett, eszett_cf:', eszett, eszett_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1 == s2:  False\n",
      "nfc_equal(s1, s2):  True\n",
      "nfc_equal(s3, s4): False\n",
      "nfc_equal('A', 'a'):  False\n",
      "\n",
      "fold_equal(s1, s2): True\n",
      "fold_equal(s3, s4): True\n",
      "fold_equal('A', 'a'): True\n"
     ]
    }
   ],
   "source": [
    "#Example 4-13. normeq.py: normalized Unicode string comparison\n",
    "from unicodedata import normalize\n",
    "def nfc_equal(str1, str2):\n",
    "    return normalize('NFC', str1) == normalize('NFC', str2)\n",
    "def fold_equal(str1, str2):\n",
    "    return (normalize('NFC', str1).casefold() == normalize('NFC', str2).casefold())\n",
    "\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "s3 = 'Straße'\n",
    "s4 = 'strasse'\n",
    "print('s1 == s2: ', s1 == s2)\n",
    "print('nfc_equal(s1, s2): ', nfc_equal(s1, s2))\n",
    "print(\"nfc_equal(s3, s4):\", nfc_equal(s3, s4))\n",
    "print(\"nfc_equal('A', 'a'): \", nfc_equal('A', 'a'))\n",
    "print()\n",
    "print(\"fold_equal(s1, s2):\", fold_equal(s1, s2))\n",
    "print(\"fold_equal(s3, s4):\", fold_equal(s3, s4))\n",
    "print(\"fold_equal('A', 'a'):\", fold_equal('A', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_txt = “Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”\n",
      "shaved = “Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "shave_marks(order) = “Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "\n",
      "norm_txt = Ζέφυρος, Zéfiro\n",
      "shaved = Ζεφυρος, Zefiro\n",
      "shave_marks(Greek) = Ζεφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "# Example 4-14. Function to remove all combining marks (module sanitize.py)\n",
    "import unicodedata\n",
    "import string\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    print(\"norm_txt =\", norm_txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    print('shaved =', shaved)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(\"shave_marks(order) =\", shave_marks(order))\n",
    "print()\n",
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "print(\"shave_marks(Greek) =\", shave_marks(Greek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shave_marks_latin(order) = “Herr Voß: • ½ cup of Œtker™ caffe latte • bowl of acai.”\n",
      "\n",
      "shave_marks_latin(Greek) = Ζέφυρος, Zefiro\n"
     ]
    }
   ],
   "source": [
    "# Example 4-16. Function to remove combining marks from Latin characters. \n",
    "import unicodedata\n",
    "import string\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue # ignore diacritic on Latin base char\n",
    "        keepers.append(c)\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(\"shave_marks_latin(order) =\", shave_marks_latin(order))\n",
    "print()\n",
    "Greek = 'Ζέφυρος, Zéfiro'\n",
    "print(\"shave_marks_latin(Greek) =\", shave_marks_latin(Greek))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_map:\n",
      " {710: 94, 8226: 45, 338: 'OE', 339: 'oe', 8212: 45, 8216: 39, 8217: 39, 8218: 39, 732: 126, 8221: 34, 8222: 34, 8224: 42, 8225: '**', 8482: '(TM)', 8230: '...', 8220: 34, 8364: '<euro>', 402: 102, 8240: '<per mille>', 8211: 45, 8249: 60, 8250: 62}\n",
      "dewinize(order) = \"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "asciize(order) = \"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "# Example 4-17. Transform some Western typographical symbols into ASCII.\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\", \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "multi_map = str.maketrans({\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "    })\n",
    "multi_map.update(single_map)\n",
    "print(\"multi_map:\\n\",  multi_map)\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks)\n",
    "\n",
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "print(\"dewinize(order) =\", dewinize(order))\n",
    "print(\"asciize(order) =\", asciize(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted(fruits):  ['Gdańsk', 'Lublin', 'Poznań', 'Warszawa', 'Łódź']\n",
      "\n",
      "sorted_fruits:  ['Gdańsk', 'Lublin', 'Łódź', 'Poznań', 'Warszawa']\n"
     ]
    }
   ],
   "source": [
    "# Example 4-19. Using the locale.strxfrm function as sort key.\n",
    "fruits = ['Poznań', 'Warszawa', 'Gdańsk', 'Łódź', 'Lublin']\n",
    "print('sorted(fruits): ', sorted(fruits))\n",
    "print()\n",
    "import locale\n",
    "locale.setlocale(locale.LC_COLLATE, 'pl_PL.UTF-8')\n",
    "sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "print('sorted_fruits: ', sorted_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted(fruits):  ['acerola', 'atemoia', 'açaí', 'caju', 'cajá']\n",
      "sorted_fruits:  ['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "# Example 4-20. Using the pyuca.Collator.sort_key method.\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "print('sorted(fruits): ', sorted(fruits))\n",
    "\n",
    "import pyuca\n",
    "coll = pyuca.Collator()\n",
    "sorted_fruits = sorted(fruits, key=coll.sort_key)\n",
    "print('sorted_fruits: ', sorted_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "#Example 4-21. Demo of Unicode database numerical character metadata. Callouts describe each column in the output\n",
    "import unicodedata\n",
    "import re\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "re_digit = re.compile(r'\\d')\n",
    "for char in sample:\n",
    "    print('U+%04x' % ord(char),\n",
    "        char.center(6),\n",
    "        're_dig' if re_digit.match(char) else '-',\n",
    "        'isdig' if char.isdigit() else '-',\n",
    "        'isnum' if char.isnumeric() else '-',\n",
    "        format(unicodedata.numeric(char), '5.2f'),\n",
    "        unicodedata.name(char),\n",
    "        sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_str:  Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.\n",
      "text_bytes: b'Ramanujan saw \\xe0\\xaf\\xa7\\xe0\\xaf\\xad\\xe0\\xaf\\xa8\\xe0\\xaf\\xaf as 1729 = 1\\xc2\\xb3 + 12\\xc2\\xb3 = 9\\xc2\\xb3 + 10\\xc2\\xb3.'\n",
      "\n",
      "Text\n",
      " 'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      " str : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      " bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      " str : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      " bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "# Example 4-22. ramanujan.py: compare behavior of simple str and bytes regular expressions\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef \"\n",
    "            \"as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "print(\"text_str: \", text_str)\n",
    "text_bytes = text_str.encode('utf_8')\n",
    "print(\"text_bytes:\", text_bytes)\n",
    "print()\n",
    "print('Text', repr(text_str), sep='\\n ')\n",
    "print('Numbers')\n",
    "print(' str :', re_numbers_str.findall(text_str))\n",
    "print(' bytes:', re_numbers_bytes.findall(text_bytes))\n",
    "print('Words')\n",
    "print(' str :', re_words_str.findall(text_str))\n",
    "print(' bytes:', re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.listdir('.'):\n",
      "FP-01 Python Data Model | str 3 - 19.ipynb\n",
      "FP-02 An array of sequences | str 19 - 63.ipynb\n",
      "FP-04 Text versus bytes | str 97 - 139.ipynb\n",
      "files\n",
      "FP-03 Dictionaries and sets | str 63 - 97.ipynb\n",
      ".ipynb_checkpoints\n",
      "digits-of-π.txt\n",
      "\n",
      "os.listdir(b'.'):\n",
      "b'FP-01 Python Data Model | str 3 - 19.ipynb'\n",
      "b'FP-02 An array of sequences | str 19 - 63.ipynb'\n",
      "b'FP-04 Text versus bytes | str 97 - 139.ipynb'\n",
      "b'files'\n",
      "b'FP-03 Dictionaries and sets | str 63 - 97.ipynb'\n",
      "b'.ipynb_checkpoints'\n",
      "b'digits-of-\\xcf\\x80.txt'\n"
     ]
    }
   ],
   "source": [
    "# Example 4-23. listdir with str and bytes arguments and results.\n",
    "import os\n",
    "print(\"os.listdir('.'):\")\n",
    "for elem in  os.listdir('.'):\n",
    "    print(elem)\n",
    "print()\n",
    "print(\"os.listdir(b'.'):\")\n",
    "for elem in os.listdir(b'.'):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_name_str:  files\n"
     ]
    }
   ],
   "source": [
    "# Example 4-24. listdir with str and bytes arguments and results.\n",
    "import os\n",
    "pi_name_bytes = os.listdir(b'.')[4]\n",
    "pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape')\n",
    "print(\"pi_name_str: \", pi_name_str)   # 'digits-of-\\udccf\\udc80.txt'\n",
    "# print(\" pi_name_bytes:\",  pi_name_bytes)  #  b'digits-of-\\xcf\\x80.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
